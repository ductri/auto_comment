{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/source/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 12:09:41.497656 140176937793280 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0813 12:09:42.283540 140176937793280 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.data_generators import text_problems, problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA.csv\ttmp\r\n"
     ]
    }
   ],
   "source": [
    "!ls /source/main/data_download/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 12:15:35.631817 139679434159872 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0813 12:15:36.449875 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0813 12:15:37.904673 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/rl/gym_utils.py:219: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0813 12:15:37.907424 139679434159872 deprecation_wrapper.py:119] From /usr/local/bin/t2t-datagen:27: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0813 12:15:37.907516 139679434159872 deprecation_wrapper.py:119] From /usr/local/bin/t2t-datagen:27: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0813 12:15:37.907590 139679434159872 deprecation_wrapper.py:119] From /usr/local/bin/t2t-datagen:28: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "I0813 12:15:37.907865 139679434159872 usr_dir.py:43] Importing user module data_for_train from path /source/main\n",
      "W0813 12:15:37.910097 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/bin/t2t_datagen.py:204: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "I0813 12:15:37.910230 139679434159872 t2t_datagen.py:207] Generating problems:\n",
      "    auto:\n",
      "      * auto_comment_problem\n",
      "W0813 12:15:37.910319 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/bin/t2t_datagen.py:156: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "I0813 12:15:37.910866 139679434159872 t2t_datagen.py:280] Generating data for auto_comment_problem.\n",
      "W0813 12:15:37.911481 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:343: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "I0813 12:15:37.911569 139679434159872 generator_utils.py:349] Generating vocab file: /source/main/data_download/output/vocab.auto_comment_problem.32768.subwords\n",
      "I0813 12:17:05.529124 139679434159872 text_encoder.py:722] Trying min_count 500\n",
      "I0813 12:17:05.547583 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:07.632295 139679434159872 text_encoder.py:866] vocab_size = 14496\n",
      "I0813 12:17:07.632477 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:09.049467 139679434159872 text_encoder.py:866] vocab_size = 8158\n",
      "I0813 12:17:09.049617 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:10.510673 139679434159872 text_encoder.py:866] vocab_size = 8382\n",
      "I0813 12:17:10.510826 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:17:11.997013 139679434159872 text_encoder.py:866] vocab_size = 8262\n",
      "I0813 12:17:12.043050 139679434159872 text_encoder.py:722] Trying min_count 250\n",
      "I0813 12:17:12.061410 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:14.155654 139679434159872 text_encoder.py:866] vocab_size = 19525\n",
      "I0813 12:17:14.155812 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:15.552798 139679434159872 text_encoder.py:866] vocab_size = 10549\n",
      "I0813 12:17:15.552949 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:16.987328 139679434159872 text_encoder.py:866] vocab_size = 10742\n",
      "I0813 12:17:16.987480 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:17:18.405950 139679434159872 text_encoder.py:866] vocab_size = 10668\n",
      "I0813 12:17:18.449954 139679434159872 text_encoder.py:722] Trying min_count 125\n",
      "I0813 12:17:18.467717 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:20.600993 139679434159872 text_encoder.py:866] vocab_size = 27003\n",
      "I0813 12:17:20.601145 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:21.907464 139679434159872 text_encoder.py:866] vocab_size = 13542\n",
      "I0813 12:17:21.907635 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:23.241106 139679434159872 text_encoder.py:866] vocab_size = 13882\n",
      "I0813 12:17:23.241311 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:17:24.551854 139679434159872 text_encoder.py:866] vocab_size = 13771\n",
      "I0813 12:17:24.588106 139679434159872 text_encoder.py:722] Trying min_count 62\n",
      "I0813 12:17:24.606354 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:26.807388 139679434159872 text_encoder.py:866] vocab_size = 37863\n",
      "I0813 12:17:26.807536 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:28.079901 139679434159872 text_encoder.py:866] vocab_size = 17612\n",
      "I0813 12:17:28.080052 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:29.371304 139679434159872 text_encoder.py:866] vocab_size = 18039\n",
      "I0813 12:17:29.371456 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:17:30.641052 139679434159872 text_encoder.py:866] vocab_size = 17885\n",
      "I0813 12:17:30.674669 139679434159872 text_encoder.py:722] Trying min_count 31\n",
      "I0813 12:17:30.693183 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:32.983370 139679434159872 text_encoder.py:866] vocab_size = 50367\n",
      "I0813 12:17:32.983518 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:34.232192 139679434159872 text_encoder.py:866] vocab_size = 21996\n",
      "I0813 12:17:34.232344 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:35.486759 139679434159872 text_encoder.py:866] vocab_size = 22352\n",
      "I0813 12:17:35.486930 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:17:36.728664 139679434159872 text_encoder.py:866] vocab_size = 22250\n",
      "I0813 12:17:36.760987 139679434159872 text_encoder.py:722] Trying min_count 15\n",
      "I0813 12:17:36.778734 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:39.136440 139679434159872 text_encoder.py:866] vocab_size = 61806\n",
      "I0813 12:17:39.136592 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:40.348031 139679434159872 text_encoder.py:866] vocab_size = 27312\n",
      "I0813 12:17:40.348181 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:41.545083 139679434159872 text_encoder.py:866] vocab_size = 27811\n",
      "I0813 12:17:41.545285 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:17:42.737337 139679434159872 text_encoder.py:866] vocab_size = 27653\n",
      "I0813 12:17:42.768311 139679434159872 text_encoder.py:722] Trying min_count 7\n",
      "I0813 12:17:42.786904 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:45.264298 139679434159872 text_encoder.py:866] vocab_size = 79356\n",
      "I0813 12:17:45.264461 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:46.425571 139679434159872 text_encoder.py:866] vocab_size = 35290\n",
      "I0813 12:17:46.425725 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:47.582732 139679434159872 text_encoder.py:866] vocab_size = 35920\n",
      "I0813 12:17:47.582881 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:17:48.724818 139679434159872 text_encoder.py:866] vocab_size = 35730\n",
      "I0813 12:17:48.753652 139679434159872 text_encoder.py:722] Trying min_count 11\n",
      "I0813 12:17:48.771747 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:51.180331 139679434159872 text_encoder.py:866] vocab_size = 67867\n",
      "I0813 12:17:51.180484 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:52.378113 139679434159872 text_encoder.py:866] vocab_size = 30167\n",
      "I0813 12:17:52.378267 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:53.581727 139679434159872 text_encoder.py:866] vocab_size = 30736\n",
      "I0813 12:17:53.581881 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:17:54.753999 139679434159872 text_encoder.py:866] vocab_size = 30582\n",
      "I0813 12:17:54.784072 139679434159872 text_encoder.py:722] Trying min_count 9\n",
      "I0813 12:17:54.801949 139679434159872 text_encoder.py:802] Iteration 0\n",
      "I0813 12:17:57.242391 139679434159872 text_encoder.py:866] vocab_size = 72796\n",
      "I0813 12:17:57.242557 139679434159872 text_encoder.py:802] Iteration 1\n",
      "I0813 12:17:58.419169 139679434159872 text_encoder.py:866] vocab_size = 32209\n",
      "I0813 12:17:58.419324 139679434159872 text_encoder.py:802] Iteration 2\n",
      "I0813 12:17:59.607480 139679434159872 text_encoder.py:866] vocab_size = 32807\n",
      "I0813 12:17:59.607646 139679434159872 text_encoder.py:802] Iteration 3\n",
      "I0813 12:18:00.761955 139679434159872 text_encoder.py:866] vocab_size = 32646\n",
      "W0813 12:18:00.820111 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/text_encoder.py:944: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0813 12:18:00.871096 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:164: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "I0813 12:18:03.477718 139679434159872 generator_utils.py:170] Generating case 0.\n",
      "I0813 12:18:47.164048 139679434159872 generator_utils.py:170] Generating case 100000.\n",
      "I0813 12:19:20.987079 139679434159872 generator_utils.py:170] Generating case 200000.\n",
      "I0813 12:20:02.786035 139679434159872 generator_utils.py:170] Generating case 300000.\n",
      "I0813 12:20:45.540949 139679434159872 generator_utils.py:170] Generating case 400000.\n",
      "W0813 12:20:50.477624 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:183: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n",
      "I0813 12:20:50.479817 139679434159872 generator_utils.py:193] Generated 412909 Examples\n",
      "I0813 12:20:50.481123 139679434159872 generator_utils.py:527] Shuffling data...\n",
      "W0813 12:20:50.481268 139679434159872 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:469: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "W0813 12:20:50.503802 139679434159872 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/generator_utils.py:513: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n",
      "I0813 12:20:52.694370 139679434159872 generator_utils.py:530] Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DATA_DIR=/source/main/data_download/output\n",
    "TMP_DIR=$DATA_DIR/tmp\n",
    "rm -rf $TMP_DIR\n",
    "mkdir -p $DATA_DIR $TMP_DIR\n",
    "\n",
    "PROBLEM=auto_comment_problem\n",
    "# Generate data\n",
    "t2t-datagen \\\n",
    "  --t2t_usr_dir=/source/main/data_for_train/ \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --tmp_dir=$TMP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  __pycache__  auto_comment_problem.py  my_problem.py  output\r\n"
     ]
    }
   ],
   "source": [
    "!ls /source/main/data_for_train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /source/main/train/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!echo  $TRAIN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "LOCALGPU=\"--train_steps=750000 --worker_gpu=1 --hparams_set=transformer_poetry\"\n",
    "\n",
    "DATA_DIR=/source/main/data_download/output\n",
    "OUTDIR=/source/main/train/output\n",
    "PROBLEM=auto_comment_problem\n",
    "rm -rf $OUTDIR\n",
    "t2t-trainer \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --t2t_usr_dir=/source/main/data_for_train/ \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=transformer_poetry \\\n",
    "  --output_dir=$OUTDIR ${LOCALGPU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo x\n",
    "tensorboard --logdir /source/main/train/output --host localhost --port 7001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
